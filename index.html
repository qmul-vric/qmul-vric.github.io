<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0055)https://qmul-survface.github.io/QMUL-SurvFace/index.htm -->
<html xmlns="http://www.w3.org/1999/xhtml">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
      <title>Vehicle Re-Identificaton in Context</title>
      <meta name="description" content="To facilitate more studies on developing face recognition models that are effective and robust 
         owing to a large number of non-target people (distractors) appearing open spaced scenes.">
      <meta name="keywords" content="QMUL SurvFace; 
         QMUL Surveillance Face Recognition Challenge; QMUL Surveillance Face Challenge;
         benchmark; computer vision;">
      <!-- Fonts and stuff -->
      <link rel="stylesheet" href="/dist/css/lib.c6986b0f7f783c49.css">
      <link href="./QMUL-SurvFace_files/project.css" rel="stylesheet">
      <link href="./QMUL-SurvFace_files/iconize.css" rel="stylesheet">
      <link href="./images/new_icon.png" rel="shortcut icon">
      <script type="text/javascript" async="" src="./QMUL-SurvFace_files/ga.js"></script>
      <link href="http://twitter.github.com/bootstrap/assets/ico/apple-touch-icon-144-precomposed.png" rel="apple-touch-icon-precomposed" sizes="144x144">
      <link href="http://twitter.github.com/bootstrap/assets/ico/apple-touch-icon-114-precomposed.png" rel="apple-touch-icon-precomposed" sizes="114x114">
      <link href="http://twitter.github.com/bootstrap/assets/ico/apple-touch-icon-72-precomposed.png" rel="apple-touch-icon-precomposed" sizes="72x72">
      <link href="http://twitter.github.com/bootstrap/assets/ico/apple-touch-icon-57-precomposed.png" rel="apple-touch-icon-precomposed">
      <style>
            .row img {
              display: inline;
              align: center;
              height: auto;
              vertical-align: middle;
            }
            .column {
              border: 2px black;
              float: left;
              width: 30%;
              padding: 10px;
            }
      </style>
   </head>
   <body>
      <div id="content">
         <div id="content-inner">
            <div class="section head">
               <p>
               <h1 id="surveillance-face-recognition-challenge">VRIC: Vehicle Re-Identificaton in Context</h1>
               </p>
               <div class="affiliations">
                  <p><a href="http://www.eecs.qmul.ac.uk/~hak32/">Aytac Kanaci</a> &nbsp; &nbsp; &nbsp; &nbsp;
                     <a href="http://www.eecs.qmul.ac.uk/~xiatian/">Xiatian Zhu</a> &nbsp; &nbsp; &nbsp; &nbsp;
                     <a href="http://www.eecs.qmul.ac.uk/~sgg/">Shaogang Gong</a>
                  <p><a href="http://vision.eecs.qmul.ac.uk/">Computer Vision Group,  </a >
                     <a href="http://www.eecs.qmul.ac.uk/">School of Electronic Engineering and Computer Science,  </a >
                     <a href="http://www.qmul.ac.uk/">Queen Mary University of London</a >
               </div>
               <ul id="tabs">
                  <li><a href="index.html" name="#tab1" id="current">Home</a></li>
                  <li><a href="summary.html" name="#tab2">Visual Summary</a></li>
                  <!-- <li><a href="https://qmul-survface.github.io/benchmark.html" name="#tab3">Leaderboard</a></li> -->
               </ul>
            </div>
            <center>
                <div class="row">
                    <div class="column" style="width:image width px; font-size:130%; text-align:center;"><img  style="width: 100%;" src="./images/detrac_examples.png" >VRIC</div>
                    <div class="column" style="width:image width px; font-size:130%; text-align:center;"><img  style="width: 100%;" src="./images/veri_examples.png" >VeRi-776</div>
                    <div class="column" style="width:image width px; font-size:130%; text-align:center;"><img  style="width: 100%;" src="./images/veid_examples.png" >VehicleID</div>
                </div>
            </center>
            <h2 id="description">Description</h2>

            <p>
            Existing vehicle re-identification (re-id) evaluation benchmarks
            consider strongly artificial test scenarios by assuming the availability of
            high quality images and fine-grained appearance at an almost constant
            image scale, reminiscent to images required for Automatic Number Plate
            Recognition, e.g. VeRi-776. 

            Such assumptions are often invalid in realistic vehicle re-id
            scenarios where arbitrarily changing image resolutions (scales) are
            the norm. This makes the existing vehicle re-id 
            benchmarks limited for testing the true performance of a re-id method. 

            In this work, we introduce a more realistic and challenging 
            vehicle re-id benchmark, called Vehicle Re-Identification in Context (VRIC).

            In contrast to existing datasets,
            VRIC is uniquely characterised by vehicle images
            subject to more realistic and unconstrained variations in
            resolution (scale), motion blur, illumination,
            occlusion, and viewpoint. %, and background clutter.

            It contains 60,434 images of 5,626 vehicle identities captured by 
            60 different cameras at heterogeneous road traffic scenes
            in both day-time and night-time.
            </p>

            <!-- <h2 id="news">News</h2> -->
            <!-- <p> -->
            <!-- <ul> -->
	       <!-- <li><strong>August 29, 2018:</strong> Updated the evaluation results of the state-of-the-art face recognition methods. </li> -->
            <!--    <li><strong>June 01, 2018:</strong> QMUL-SurvFace dataset, the evaluation protocol, and test codes are released. </li> -->
            <!-- </ul> -->
            <!-- </p> -->

            <h2 id="download">Download</h2>
            <p>VRIC Dataset (389MB): 
               [<a href="https://drive.google.com/open?id=13ch6BPaexlKt8gXB_I8aX7p1G3yPm2Bl" target="_blank">Google Drive</a>] 
               [<a href="https://pan.baidu.com/s/1O55042SMxLYqBWdGGQ_4_g" target="_blank">Baidu Cloud</a>]
            </p>

            <h2 id="citation">Citation</h2>
			<div>
            <pre>
	    	<em>Vehicle Re-Identificaiton in Context.</em>
            Aytac Kanaci, Xiatian Zhu and Shaogang Gong.
            Technical Report, 2018. 
            <a href="">Paper</a> 
            <!-- <a href="QMUL-SurvFace_bibtex.html">Bibtex</a> --> 
            </pre>
			</div>

			<div class="entry"><p class="text-justify">
            <pre>
            @inproceedings{2018gcpr-Kanaci,
            author    = {Aytac Kanaci and
                         Xiatian Zhu and
                         Shaogang Gong},
            title     = {Vehicle Re-Identification in Context},
            booktitle = {Pattern Recognition - 40th German Conference, {GCPR} 2018, Stuttgart,
                         Germany, September 10-12, 2018, Proceedings},
            year      = {2018}
            }
            </pre>
			</div>

            <h2 id="Related Datasets">Related Datasets</h2>
            <p>VRIC is a result of a conversion of from UA-DETRAC vehicle tracking dataset. A conversion using the ground truth tracking identities were used in the creating of the re-identification labels. More details can be found in our <a href="https://arxiv.org/pdf/1804.09691.pdf">paper.</a></p>


            <h2 id="Licence">Licence</h2>
            <p>
               All the images were collected from <a href="http://detrac-db.rit.albany.edu/">UA-DETRAC</a>                                                                                                                                
               and the copyright belongs to the original owners. 
            </p>
			<div class="entry"><p class="text-justify">
            <pre>
@article{DETRAC:CoRR:WenDCLCQLYL15,
  author    = {Longyin Wen and Dawei Du and Zhaowei Cai and Zhen Lei and Ming{-}Ching Chang and
               Honggang Qi and Jongwoo Lim and Ming{-}Hsuan Yang and Siwei Lyu},
  title     = { {UA-DETRAC:} {A} New Benchmark and Protocol for Multi-Object Detection and Tracking},
  journal   = {arXiv CoRR},
  volume    = {abs/1511.04136},
  year      = {2015}
}          
			</pre>
			</div>
            <h2 id="contact">Contact</h2>
            <p>Please feel free to send any questions, comments, and evaluation results with a brief method description to Aytac Kanaci at <strong>a.kanaci@qmul.ac.uk</strong>.</p>
            <div class="footer">
	        <div class="clearfix">
		  <div class="leftbox">
                      <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=ZMooCrePyovHLZMPtSdcJlZgBCLOXkBOLp3sH4Fn5b0&cl=ffffff&w=a"></script>
		  </div>

		  <div class="rightbox">
		      <a href="https://m.maploco.com/details/fa55v386"><img style="border:0px; width:220px;" src="https://www.maploco.com/vmap/s/9848598.png" alt="Locations of Site Visitors" title="Locations of Site Visitors"/></a>  
		  </div>
		</div>
           </div>
         </div>
         
      </div>
   </body>
</html>
